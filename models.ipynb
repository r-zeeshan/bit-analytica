{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is going to contain the dataset, and model(s) which is going to be used to predict the open and low for the next day. So far, a dataset has been created, and various techincal indicators for bitcoin price movement have been added into it, the aggregated sentiment scores, generated using FinBERT are also the feature in my final dataset. The main focus of this notebook would be to predict open and low for the next day without any further normalization or preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting the Complete Data\n",
    "from btc_data_pipeline import BitcoinDataPipeline\n",
    "import pandas as pd\n",
    "\n",
    "bdp = BitcoinDataPipeline()\n",
    "btc_data = bdp.getLatestBitcoinData()\n",
    "btc_data = btc_data.drop(index='2024-07-10' , axis=0)\n",
    "\n",
    "sentiment_data = pd.read_csv('data/sentiment_scores.csv', parse_dates=['Date'], index_col='Date')\n",
    "sentiment_data.index = pd.to_datetime(sentiment_data.index)\n",
    "sentiment_data.index = sentiment_data.index.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = btc_data.merge(sentiment_data, on='Date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(index=pd.to_datetime('2024-07-09'), axis=0)\n",
    "data['aggregated_sentiment'] = data['aggregated_sentiment'].ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get our target variables, I can simply shift the high and low by -1, this would provide me the target columns, as the open and low for the next day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['y_high'] = data['High'].shift(-1)\n",
    "data['y_low'] = data['Low'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(index=pd.to_datetime('2024-07-08'), axis=0)\n",
    "data.tail(3) ### Last row has target variables as Nan, I will simply drop it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting up Model Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def calculate_mae(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the mean absolute error (MAE) between the true values and the predicted values.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (array-like): The true values.\n",
    "    y_pred (array-like): The predicted values.\n",
    "\n",
    "    Returns:\n",
    "    float: The mean absolute error (MAE) between the true values and the predicted values.\n",
    "    \"\"\"\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the Root Mean Squared Error (RMSE) between the true values and the predicted values.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: array-like, true values\n",
    "    - y_pred: array-like, predicted values\n",
    "\n",
    "    Returns:\n",
    "    - rmse: float, the RMSE value\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def calculate_mape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Absolute Percentage Error (MAPE) between the true and predicted values.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true (array-like): The true values.\n",
    "    - y_pred (array-like): The predicted values.\n",
    "\n",
    "    Returns:\n",
    "    - mape (float): The calculated MAPE.\n",
    "\n",
    "    \"\"\"\n",
    "    return np.mean(np.abs((y_true, y_pred)/y_true)) * 100\n",
    "\n",
    "def calculate_r2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the R-squared (coefficient of determination) score.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: array-like of shape (n_samples,)\n",
    "        The true target values.\n",
    "    - y_pred: array-like of shape (n_samples,)\n",
    "        The predicted target values.\n",
    "\n",
    "    Returns:\n",
    "    - r2_score: float\n",
    "        The R-squared score.\n",
    "\n",
    "    \"\"\"\n",
    "    return r2_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "def evaluate_model(y_true_high, y_pred_high, y_true_low, y_pred_low):\n",
    "        \"\"\"\n",
    "        Evaluate the performance of a model by calculating various metrics for high and low values.\n",
    "\n",
    "        Parameters:\n",
    "        - y_true_high (array-like): True high values.\n",
    "        - y_pred_high (array-like): Predicted high values.\n",
    "        - y_true_low (array-like): True low values.\n",
    "        - y_pred_low (array-like): Predicted low values.\n",
    "\n",
    "        Returns:\n",
    "        - metrics (dict): A dictionary containing the calculated metrics for high and low values.\n",
    "            The keys of the dictionary are:\n",
    "            - 'High_MAE': Mean Absolute Error for high values.\n",
    "            - 'Low_MAE': Mean Absolute Error for low values.\n",
    "            - 'High_RMSE': Root Mean Squared Error for high values.\n",
    "            - 'Low_RMSE': Root Mean Squared Error for low values.\n",
    "            - 'High_MAPE': Mean Absolute Percentage Error for high values.\n",
    "            - 'Low_MAPE': Mean Absolute Percentage Error for low values.\n",
    "            - 'High_R2': R-squared score for high values.\n",
    "            - 'Low_R2': R-squared score for low values.\n",
    "        \"\"\"\n",
    "        metrics = {\n",
    "                'High_MAE': calculate_mae(y_true_high, y_pred_high),\n",
    "                'Low_MAE': calculate_mae(y_true_low, y_pred_low),\n",
    "                'High_RMSE': calculate_rmse(y_true_high, y_pred_high),\n",
    "                'Low_RMSE': calculate_rmse(y_true_low, y_pred_low),\n",
    "                'High_MAPE': calculate_mape(y_true_high, y_pred_high),\n",
    "                'Low_MAPE': calculate_mape(y_true_low, y_pred_low),\n",
    "                'High_R2': calculate_r2(y_true_high, y_pred_high),\n",
    "                'Low_R2': calculate_r2(y_true_low, y_pred_low),\n",
    "        }\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating Multiple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### Preparing the data for XGBoost\n",
    "y = data[['y_high', 'y_low']]\n",
    "X = data.drop(columns=['y_high', 'y_low'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, train_size=0.75, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train separate XGBoost models for y_high and y_low.\n",
    "import xgboost as xgb\n",
    "\n",
    "### Converting data into DMatrix, optimized for XGBoost\n",
    "dtrain_high = xgb.DMatrix(X_train, label=y_train['y_high'])\n",
    "dtrain_low = xgb.DMatrix(X_train, label=y_train['y_low'])\n",
    "dtest_high = xgb.DMatrix(X_test)\n",
    "dtest_low = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameters for the XGBoost Model\n",
    "params = {\n",
    "    'objective' : 'reg:squarederror',\n",
    "    'eval_metric' : 'rmse'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_high = xgb.train(params, dtrain_high, num_boost_round=100)\n",
    "xgb_model_low = xgb.train(params, dtrain_low, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_high = xgb_model_high.predict(dtest_high)\n",
    "y_pred_low = xgb_model_low.predict(dtest_low)\n",
    "\n",
    "# Combine predictions into a DataFrame\n",
    "y_pred = pd.DataFrame({\n",
    "    'y_pred_high': y_pred_high,\n",
    "    'y_pred_low': y_pred_low\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_high = y_test['y_high']\n",
    "y_test_low = y_test['y_low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "metrics_xgb = evaluate_model(y_test_high.values, y_pred_high, y_test_low.values, y_pred_low)\n",
    "print(metrics_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_predictions_vs_actuals(dates, actuals, predictions, title):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add actual values\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates,\n",
    "        y=actuals,\n",
    "        mode='lines',\n",
    "        name='Actual',\n",
    "        line=dict(color='blue')\n",
    "    ))\n",
    "\n",
    "    # Add predicted values\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates,\n",
    "        y=predictions,\n",
    "        mode='lines',\n",
    "        name='Predicted',\n",
    "        line=dict(color='red')\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Price (USD)',\n",
    "        template='plotly_dark'\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "dates = y_test.index\n",
    "\n",
    "# Plot for High Prices\n",
    "fig_high = plot_predictions_vs_actuals(dates, y_test['y_high'], y_pred['y_pred_high'], 'Actual vs Predicted High Prices')\n",
    "fig_high.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_high = plot_predictions_vs_actuals(dates, y_test['y_low'], y_pred['y_pred_low'], 'Actual vs Predicted Low Prices')\n",
    "fig_high.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "### Model 2: Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### Preparing the data for Gradient Boosting Machine\n",
    "y = data[['y_high', 'y_low']]\n",
    "X = data.drop(columns=['y_high', 'y_low'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, train_size=0.75, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbm_high = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "gbm_low = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "gbm_high.fit(X_train, y_train['y_high'])\n",
    "gbm_low.fit(X_train, y_train['y_low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_high = gbm_high.predict(X_test)\n",
    "y_pred_low = gbm_high.predict(X_test)\n",
    "\n",
    "y_pred_gbm = pd.DataFrame({\n",
    "    'y_pred_high': y_pred_high,\n",
    "    'y_pred_low': y_pred_low\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_high = y_test['y_high']\n",
    "y_test_low = y_test['y_low']\n",
    "\n",
    "\n",
    "metrics_gbm = evaluate_model(y_test_high.values, y_pred_high, y_test_low.values, y_pred_low)\n",
    "metrics_gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for High Prices\n",
    "fig_high_gbm = plot_predictions_vs_actuals(dates, y_test['y_high'], y_pred_gbm['y_pred_high'], 'GBM: Actual vs Predicted High Prices')\n",
    "fig_high_gbm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for Low Prices\n",
    "fig_low_gbm = plot_predictions_vs_actuals(dates, y_test['y_low'], y_pred_gbm['y_pred_low'], 'GBM: Actual vs Predicted Low Prices')\n",
    "fig_low_gbm.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = data[['y_high', 'y_low']]\n",
    "X = data.drop(columns=['y_high', 'y_low'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, train_size=0.75, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Scale the target variables separately\n",
    "y_scaler_high = MinMaxScaler()\n",
    "y_train_high_scaled = y_scaler_high.fit_transform(y_train['y_high'].values.reshape(-1, 1))\n",
    "y_test_high_scaled = y_scaler_high.transform(y_test['y_high'].values.reshape(-1, 1))\n",
    "\n",
    "y_scaler_low = MinMaxScaler()\n",
    "y_train_low_scaled = y_scaler_low.fit_transform(y_train['y_low'].values.reshape(-1, 1))\n",
    "y_test_low_scaled = y_scaler_low.transform(y_test['y_low'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving the Scalers\n",
    "os.makedirs('models/scalers/', exist_ok=True)\n",
    "\n",
    "with open('models/scalers/x_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(f)\n",
    "\n",
    "with open('models/scalers/y_high_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(f)\n",
    "\n",
    "with open('models/scalers/y_low_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input to be 3D (samples, timesteps, features)\n",
    "X_train_scaled_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_scaled_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Bidirectional, LSTM, GRU, Input\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(input_shape))\n",
    "    model.add(Bidirectional(LSTM(50, return_sequences=True)))\n",
    "    model.add(GRU(50))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer for high or low price prediction\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Build models for high and low predictions\n",
    "input_shape = (X_train_scaled_lstm.shape[1], X_train_scaled_lstm.shape[2])\n",
    "lstm_model_high = build_model(input_shape)\n",
    "lstm_model_low = build_model(input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model for high price prediction\n",
    "history_high = lstm_model_high.fit(X_train_scaled_lstm, y_train_high_scaled, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model for low price prediction\n",
    "history_low = lstm_model_low.fit(X_train_scaled_lstm, y_train_low_scaled, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict high and low prices\n",
    "y_pred_high_scaled = lstm_model_high.predict(X_test_scaled_lstm)\n",
    "y_pred_low_scaled = lstm_model_low.predict(X_test_scaled_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform the predictions\n",
    "y_pred_high = y_scaler_high.inverse_transform(y_pred_high_scaled).flatten()\n",
    "y_pred_low = y_scaler_low.inverse_transform(y_pred_low_scaled).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract true values for evaluation\n",
    "y_test_high = y_test['y_high']\n",
    "y_test_low = y_test['y_low']\n",
    "\n",
    "# Evaluate the model\n",
    "metrics_lstm = evaluate_model(y_test_high.values, y_pred_high, y_test_low.values, y_pred_low)\n",
    "print(metrics_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for High Prices\n",
    "fig_high_dl = plot_predictions_vs_actuals(dates, y_test['y_high'], y_pred_high, 'BiDirectional LSTM + GRU: Actual vs Predicted High Prices')\n",
    "fig_high_dl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for Low Prices\n",
    "fig_low_dl = plot_predictions_vs_actuals(dates, y_test['y_low'], y_pred_low, 'BiDirectional LSTM + GRU: Actual vs Predicted Low Prices')\n",
    "fig_low_dl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: TabNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using the builtin implementation of TabNet from Pytorch\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "### Initializing the models\n",
    "tabnet_model_high = TabNetRegressor()\n",
    "tabnet_model_low = TabNetRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training the model for predicting high\n",
    "tabnet_model_high.fit(\n",
    "    X_train_scaled, y_train_high_scaled,\n",
    "    eval_set=[(X_test_scaled, y_test_high_scaled)],\n",
    "    max_epochs=300,\n",
    "    patience=30,\n",
    "    batch_size=32,\n",
    "    virtual_batch_size=32,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training the model for predicting Low\n",
    "tabnet_model_low.fit(\n",
    "    X_train_scaled, y_train_low_scaled,\n",
    "    eval_set=[(X_test_scaled, y_test_low_scaled)],\n",
    "    max_epochs=300,\n",
    "    patience=30,\n",
    "    batch_size=32,\n",
    "    virtual_batch_size=32,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict high and low prices\n",
    "y_pred_high_scaled = tabnet_model_high.predict(X_test_scaled)\n",
    "y_pred_low_scaled = tabnet_model_low.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "y_pred_high = y_scaler_high.inverse_transform(y_pred_high_scaled).flatten()\n",
    "y_pred_low = y_scaler_low.inverse_transform(y_pred_low_scaled).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract true values for evaluation\n",
    "y_test_high = y_test['y_high']\n",
    "y_test_low = y_test['y_low']\n",
    "\n",
    "# Evaluate the model\n",
    "metrics_tabnet = evaluate_model(y_test_high.values, y_pred_high, y_test_low.values, y_pred_low)\n",
    "print(metrics_tabnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for High Prices\n",
    "fig_high_tabnet = plot_predictions_vs_actuals(dates, y_test['y_high'], y_pred_high, 'TabNet: Actual vs Predicted High Prices')\n",
    "fig_high_tabnet.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for Low Prices\n",
    "fig_low_tabnet = plot_predictions_vs_actuals(dates, y_test['y_low'], y_pred_low, 'TabNet: Actual vs Predicted Low Prices')\n",
    "fig_low_tabnet.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparing all 4 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using plotly to visulise and compare the 4 models\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['High_MAE', 'Low_MAE', 'High_RMSE', 'Low_RMSE', 'High_MAPE', 'Low_MAPE', 'High_R2', 'Low_R2'],\n",
    "    'XGBoost': [metrics_xgb['High_MAE'], metrics_xgb['Low_MAE'], metrics_xgb['High_RMSE'], metrics_xgb['Low_RMSE'], metrics_xgb['High_MAPE'], metrics_xgb['Low_MAPE'], metrics_xgb['High_R2'], metrics_xgb['Low_R2']],\n",
    "    'GBM': [metrics_gbm['High_MAE'], metrics_gbm['Low_MAE'], metrics_gbm['High_RMSE'], metrics_gbm['Low_RMSE'], metrics_gbm['High_MAPE'], metrics_gbm['Low_MAPE'], metrics_gbm['High_R2'], metrics_gbm['Low_R2']],\n",
    "    'LSTM': [metrics_lstm['High_MAE'], metrics_lstm['Low_MAE'], metrics_lstm['High_RMSE'], metrics_lstm['Low_RMSE'], metrics_lstm['High_MAPE'], metrics_lstm['Low_MAPE'], metrics_lstm['High_R2'], metrics_lstm['Low_R2']],\n",
    "    'TabNet': [metrics_tabnet['High_MAE'], metrics_tabnet['Low_MAE'], metrics_tabnet['High_RMSE'], metrics_tabnet['Low_RMSE'], metrics_tabnet['High_MAPE'], metrics_tabnet['Low_MAPE'], metrics_tabnet['High_R2'], metrics_tabnet['Low_R2']]\n",
    "})\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ranking the models for each metric\n",
    "rankings = metrics_df.copy()\n",
    "for metric in rankings['Metric']:\n",
    "    # For MAE, RMSE, MAPE: lower is better\n",
    "    if 'MAE' in metric or 'RMSE' in metric or 'MAPE' in metric:\n",
    "        rankings.loc[rankings['Metric'] == metric, ['XGBoost', 'GBM', 'LSTM', 'TabNet']] = rankings.loc[rankings['Metric'] == metric, ['XGBoost', 'GBM', 'LSTM', 'TabNet']].rank(axis=1, method='min')\n",
    "    # For R2: higher is better\n",
    "    else:\n",
    "        rankings.loc[rankings['Metric'] == metric, ['XGBoost', 'GBM', 'LSTM', 'TabNet']] = rankings.loc[rankings['Metric'] == metric, ['XGBoost', 'GBM', 'LSTM', 'TabNet']].rank(axis=1, method='min', ascending=False)\n",
    "\n",
    "# Plotting function for combined High and Low metrics\n",
    "def plot_ranking_chart(rankings_df, title):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for model in ['XGBoost', 'GBM', 'LSTM', 'TabNet']:\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=rankings_df['Metric'],\n",
    "            y=rankings_df[model],\n",
    "            name=model\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title='Metric',\n",
    "        yaxis_title='Rank',\n",
    "        template='plotly_dark',\n",
    "        barmode='group'\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Plot the ranking chart\n",
    "plot_ranking_chart(rankings, 'Model Rankings by Metric')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the model development, the main model I choose for predicting the high and low are as follows:\n",
    "1. For Predicting High: LSTM Model\n",
    "2. For Predicting Low: TabNet Model\n",
    "\n",
    "Next step is to basically Train these two selected models on the complete dataset before deploying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[['y_high', 'y_low']]\n",
    "X = data.drop(columns=['y_high', 'y_low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normalzing the Data for the models\n",
    "import pickle\n",
    "with open('models/scalers/x_scaler.pkl', 'rb') as f:\n",
    "    x_scaler = pickle.load(f)\n",
    "\n",
    "with open('models/scalers/y_high_scaler.pkl', 'rb') as f:\n",
    "    y_high_scaler = pickle.load(f)\n",
    "\n",
    "with open('models/scalers/y_low_scaler.pkl', 'rb') as f:\n",
    "    y_low_scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = x_scaler.transform(X)\n",
    "y_high_scaled = y_high_scaler.transform(y['y_high'].values.reshape(-1, 1))\n",
    "y_low_scaled = y_low_scaler.transform(y['y_low'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_lstm = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_scaled_lstm.shape[1], X_scaled_lstm.shape[2])\n",
    "lstm_model = build_model(input_shape)\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history_lstm = lstm_model.fit(X_scaled_lstm, y_high_scaled, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving the Model\n",
    "os.makedirs('models/high/', exist_ok=True)\n",
    "lstm_model.save('models/high/high.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabnet_model = TabNetRegressor()\n",
    "\n",
    "tabnet_model.fit(\n",
    "    X_scaled, y_low_scaled,\n",
    "    max_epochs=300,\n",
    "    patience=30,\n",
    "    batch_size=32,\n",
    "    virtual_batch_size=32,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving the Model\n",
    "os.makedirs('models/low/', exist_ok=True)\n",
    "tabnet_model.save_model('models/high/low')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.06",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
